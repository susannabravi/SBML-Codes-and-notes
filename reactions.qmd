---
title: "Reactions Analysis"
format: 
    html:
        code-fold: true
        code-tools: true
jupyter: python3
---



```{python}
#| echo: false
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import numpy as np
from descriptive_stat_functions import plot_data, print_stats, extract_references
from IPython.display import display, Markdown
ggplot_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
```

While pathways (file_id) are all unique, the reactions inside them are not, so if I group for reaction_id I get less reactions than the total length of the dataframe.

```{python}
# Read the big dataset 
df = pd.read_parquet("./reactions.parquet")
print(f"\nUnique values for each variable:\n{df.nunique()}")
```

In the original data there are no duplicates because the cobination of file_id and reaction_id are all uniques.
```{python}
print(f"\nNumber of rows in the original data:{len(df)}")
df = df.drop_duplicates().reset_index(drop=True)
print(f"\nNumber of rows after dropping duplicates:{len(df)}")
```
Do not consider the column file_id in order to see the duplicates.
```{python}
# Sort the data and display the first rows
# Temporarily drop file_id to check for true duplicates
df_dedup = df.drop_duplicates(subset=[col for col in df.columns if col != 'file_id']).reset_index(drop=True)

print(f"\nOriginal number of rows: {len(df)}")
print(f"Number of rows after deduplication (excluding file_id): {len(df_dedup)}")
print(f"Removed {len(df) - len(df_dedup)} duplicate rows.")

```

Looking at the sorted dataframe it's possible to see that the only thing that change is the _meta-id_ of the snippet column. (Already deleted).
```{python}
print("First rows of sorted dataset by reaction_id:")
df_dedup.sort_values(by='reaction_id').head(10)
```

It's possible to see that there are still duplicate reaction ids and the reason in that the snippet is the same but with the rows in different order.

```{python}
#| output: asis
sorted_df = df_dedup.sort_values(by='reaction_id')

# Show original notes (formatted as text)
for i in range(1,3):
    display(Markdown(f"**Original notes at index {i}:**  \n{sorted_df['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(1,3):
    snippet = sorted_df['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

```{python}
# Show original notes (formatted as text)
for i in range(10,12):
    display(Markdown(f"**Original notes at index {i}:**  \n{sorted_df['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(10,12):
    snippet = sorted_df['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

```{python}
# Show original notes (formatted as text)
for i in range(16,18):
    display(Markdown(f"**Original notes at index {i}:**  \n{sorted_df['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(16,18):
    snippet = sorted_df['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

```{python}
# Show original notes (formatted as text)
for i in range(18,20):
    display(Markdown(f"**Original notes at index {i}:**  \n{sorted_df['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(18,20):
    snippet = sorted_df['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

# Reaction_id and notes combined unique values
Each reaction_id is associated with only one notes while the same note can be associated to different reactions.
Grouping by reaction_id and counting the number of unique notes for it: 
```{python}
# Group by reaction_id and count the number of unique notes for each
different_notes = df.groupby('reaction_id')['notes'].nunique()

# Filter to keep only reaction_ids with more than 1 unique note
reaction_ids_with_different_notes = different_notes[different_notes > 1]

print(f"Number of unique reaction_ids: {len(different_notes)}")
print(f"Number of reaction with more than one note associated: {len(reaction_ids_with_different_notes)}")
```

Grouping by note and counting the number of unique reaction_id for it: 
```{python}
# Group by 'notes' and count the number of unique reaction_id values
multiple_reactions_per_note = df_dedup.groupby('notes')['reaction_id'].nunique()

# Filter to keep only notes linked to more than one reaction_id
notes_with_multiple_reactions = multiple_reactions_per_note[multiple_reactions_per_note > 1]

# Display the notes (and how many reaction_ids they are linked to)
print(f"Number of unique notes: {len(multiple_reactions_per_note)}")
print(f"Number of notes with more than one reaction associated: {len(notes_with_multiple_reactions)}")
```
```{python}
# Filter the original DataFrame to only include those notes
conflicting_notes_rows = df_dedup[df_dedup['notes'].isin(notes_with_multiple_reactions.index)]
print(f"Number of rows of the dataset composed by duplicated notes: {len(conflicting_notes_rows)}")
print(f"Number of unique values of the dataset composed by duplicated notes:\n{conflicting_notes_rows.nunique()}")
```

```{python}
conflicting_notes_rows_sorted = conflicting_notes_rows[["file_id","reaction_id","original_notes","snippet"]].sort_values(by='original_notes')
conflicting_notes_rows_sorted.head(20)
```

```{python}
# Show original notes (formatted as text)
for i in range(0,4):
    display(Markdown(f"**Original notes at index {i}:**  \n{conflicting_notes_rows_sorted['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(0,4):
    snippet = conflicting_notes_rows_sorted['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

```{python}
# Show original notes (formatted as text)
for i in range(4,11):
    display(Markdown(f"**Original notes at index {i}:**  \n{conflicting_notes_rows_sorted['original_notes'].iloc[i]} \n"))

# Show snippet (formatted as code block)
for i in range(4,11):
    snippet = conflicting_notes_rows_sorted['snippet'].iloc[i]
    display(Markdown(f"**Snippet at index {i}:**\n```xml\n{snippet}\n```"))
```

# References per reaction distribution
```{python}
df_dedup['parsed_references'] = df_dedup['only_references'].apply(extract_references)
# How many references per reaction
references_per_reaction = df_dedup.groupby('reaction_id')['parsed_references'].apply(
    lambda lists: sum(len(ref) for ref in lists)
)
# How many unique references per file 
unique_refs_per_reactions = df_dedup.groupby('reaction_id')['parsed_references'].apply(
    lambda ref_lists: len(set(ref for refs in ref_lists for ref in refs))
)

# Results
print("Total number of references per reaction:") 
references_per_reaction.head(10)
```

```{python}
print("Unique references per reaction:") 
unique_refs_per_reactions.head(10)
```

```{python}
plot_data(data = references_per_reaction,
          outputname = "fig10.png",
          title = "Referencese per reactions",
          xlabel = "References",
          boxplot = True
          )
plot_data(data = references_per_reaction,
          outputname = "fig11.png",
          title = "Referencese per reactions with log scale x",
          xlabel = "References",
          boxplot = True,
          logscale_x = True,
          n_bins = 15
          )
plot_data(data = references_per_reaction,
          outputname = "fig12.png",
          title = "Referencese per reactions cutted",
          xlabel = "References",
          boxplot = True,
          cut_percentile=(0,90),
          n_bins = 15
          )

print("Raw data statistics")
print_stats(references_per_reaction)
```

## References without duplicates per reaction distribution
```{python}
plot_data(data = unique_refs_per_reactions,
          outputname = "fig10.png",
          title = "Referencese per reactions",
          xlabel = "References",
          boxplot = True
          )
plot_data(data = unique_refs_per_reactions,
          outputname = "fig11.png",
          title = "Referencese per reactions with log scale x",
          xlabel = "References",
          boxplot = True,
          logscale_x = True,
          n_bins = 15
          )
plot_data(data = unique_refs_per_reactions,
          outputname = "fig12.png",
          title = "Referencese per reactions cutted",
          xlabel = "References",
          boxplot = True,
          cut_percentile=(0,90),
          n_bins = 15
          )

print("Unique references raw data statistics")
print_stats(unique_refs_per_reactions)
```
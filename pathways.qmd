---
title: "Pathways Analysis"
format: 
    html:
        code-fold: true
        code-tools: true
jupyter: python3
---


```{python}
#| echo: false
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import numpy as np
from descriptive_stat_functions import plot_data, print_stats, extract_references
from IPython.display import display, Markdown
from collections import Counter
ggplot_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
```

Analysis at Pathway level.
```{python}
# Read the big dataset 
df = pd.read_parquet("./pathways.parquet")
print(f"Number of rows in the original data:{len(df)}")
df = df.drop_duplicates(subset=[
    'file_id', 'reaction_count', 'notes_count',
    'total_references', 'unique_references'
]).reset_index(drop=True)
print(f"Number of rows after dropping duplicates:{len(df)}")
print(f"Columns:{df.columns}")
df.head(15)
```

# Reactions per pathways
Counting how many reactions there are per each pathway and analyzing its distibution.

### Raw data
```{python}
# Read Reaction Count data
reaction_count = df['reaction_count']
# Find the row with the maximum reaction count
max_idx = df['reaction_count'].idxmax()  
max_row = df.loc[max_idx]   

print(f"\nFile with Maximum Reaction Count: {max_row['file_id']}")
print(f"reaction_count: {max_row['reaction_count']}")
#R-HSA-162582.sbml
```

[R-HSA-162582](https://reactome.org/content/detail/R-HSA-162582)

```{python}
# Sort the DataFrame by reaction_count in descending order
sorted_df = df.sort_values(by='reaction_count', ascending=False)

# Print the top files
print("\nFiles sorted by reaction_count (descending):")
sorted_df.head(15)
```


```{python}
# Summary statistics
plot_data(reaction_count, boxplot = True)
print_stats(reaction_count)
```

### Log-scaled data
Log10 transformation of the data
```{python}
# Log-scaled data 
plot_data(reaction_count, 
          logscale_x = True, 
          outputname = "fig2.png", 
          boxplot = True, 
          xlabel= "Log10 Reactions")
```

### Filtered data 90th percentile 
```{python}
plot_data(data =  df['reaction_count'],
          outputname = "fig6.png",
          title = "Reactions per file cutted",
          xlabel = "References",
          cut_percentile=(0,90),
          boxplot = True
          )

```

# References per Pathway distribution

```{python}
display(Markdown(f"\n**First reference:**\n{df['all_references'].iloc[0]}"))
print(f"\nTotal number of references in all files (with duplicates): {sum(df.total_references.values)}")
print(f"Total number of unique references across all files: {sum(df.unique_references.values)}")
```

```{python}
# Flatten all references across files into a single list
all_refs_flat = df['all_references'].explode()
# Count frequency of each reference
ref_counts = Counter(all_refs_flat)

reference_links = {
    "Bagci et al. 2020": "https://pubmed.ncbi.nlm.nih.gov/31871319/",
    "Müller et al. 2020": "https://www.nature.com/articles/s41586-020-2474-7",
    "Jaiswal et al. 2013": "https://pubmed.ncbi.nlm.nih.gov/23711700/", 
}


top_n = 3
for ref, count in ref_counts.most_common(top_n):
    url = reference_links.get(ref)
    link_md = f"[Link]({url})" if url else "_Link not available_"
    display(Markdown(f"**Reference:** {ref} **Citations:** {count} **{link_md}** \n"))
```

(note: va bene che il primo articolo abbia 6994 e non 10617 perchè il primo è l'articolo più citato tra tutti i file mentre il secondo numero è il massimo numero di citazioni in un file.)

```{python}
plot_data(data = df['total_references'],
          outputname = "fig4.png",
          title = "References per file (with duplicates)",
          xlabel = "References",
          color = ggplot_colors[1],
          boxplot = True
          )
plot_data(data =  df['total_references'],
          outputname = "fig5.png",
          title = "Referencese per file with log scale x (with duplicates)",
          xlabel = "log(References)",
          color = ggplot_colors[1],
          boxplot = True,
          logscale_x = True
          )
plot_data(data =  df['total_references'],
          outputname = "fig6.png",
          title = "Referencese per file cutted (with duplicates)",
          xlabel = "References",
          color = ggplot_colors[1],
          cut_percentile=(0,90),
          boxplot = True
          )

print("Summary statistic of references per file with duplicates, raw data: \n")
print_stats(df['total_references'])
```

```{python}
plot_data(data = df['unique_references'],
          outputname = "fig7.png",
          title = "References per file (without duplicates)",
          xlabel = "References",
          color = ggplot_colors[2],
          boxplot = True
          )
plot_data(data =  df['unique_references'],
          outputname = "fig8.png",
          title = "Referencese per file with log scale x (without duplicates)",
          xlabel = "log(References)",
          color = ggplot_colors[2],
          boxplot = True,
          logscale_x = True
          )
plot_data(data =  df['unique_references'],
          outputname = "fig9.png",
          title = "Referencese per file cutted (without duplicates)",
          xlabel = "References",
          color = ggplot_colors[2],
          boxplot = True,
          cut_percentile=(0,90)
          )

print("Summary statistic of references per file without duplicates, raw data: \n")
print_stats(df['unique_references'])
```

## Pathways without any reference
```{python}
zero_references_count = (df['total_references'] == 0).sum()
print(f"Number of file_id with total_references equal to zero: {zero_references_count}")
print("Sorted data by ascending unique_references and descending reaction_count")
df.sort_values(by=['unique_references','reaction_count'], ascending=[True, False]).head(15)
```
